#!/usr/bin/env python3
"""
Script de validation compl√®te du Sprint 1.

Ce script valide:
1. ‚úÖ Utilisation de SurrealDB (pas SQLite)
2. ‚úÖ Patterns officiels Agno (Agent, Team, Workflow)
3. ‚úÖ Support Ollama avec diff√©rents mod√®les
4. ‚úÖ Support Claude API
5. ‚úÖ Support MLX via OpenAILike (OpenAI-compatible)
6. ‚úÖ Persistance automatique dans SurrealDB
7. ‚úÖ Code propre et bien document√©

Usage:
    # Tester Ollama (d√©faut: mistral)
    uv run python test_sprint1_validation.py

    # Tester un mod√®le sp√©cifique
    MODEL=ollama:phi3 uv run python test_sprint1_validation.py
    MODEL=anthropic:claude-sonnet-4-5-20250929 uv run python test_sprint1_validation.py
    MODEL=mlx:mlx-community/Phi-3-mini-4k-instruct-4bit uv run python test_sprint1_validation.py

    # Tester tous les mod√®les Ollama recommand√©s
    TEST_ALL_OLLAMA=1 uv run python test_sprint1_validation.py

Pr√©requis:
    1. SurrealDB: docker-compose up -d surrealdb
    2. Ollama: ollama serve (terminal s√©par√©)
    3. Claude API: export ANTHROPIC_API_KEY=sk-ant-...
    4. MLX: mlx_lm.server --model MODEL_PATH --port 8080
"""

import asyncio
import logging
import os
import sys
from datetime import datetime, timezone
from pathlib import Path

# Ajouter le r√©pertoire parent au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent))

from config.models import (
    get_recommended_ollama_models,
    print_models_info,
)
from services.model_factory import create_model, validate_model_string
from services.agno_db_service import get_agno_db_service
from workflows.analyse_dossier import WorkflowAnalyseDossier
from config import settings

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ========================================
# Validation de l'environnement
# ========================================

def validate_environment():
    """Valide que l'environnement est correctement configur√©."""
    print("=" * 80)
    print("VALIDATION DE L'ENVIRONNEMENT - SPRINT 1")
    print("=" * 80)

    checks = []

    # 1. SurrealDB
    print("\nüìä 1. V√©rification SurrealDB...")
    print(f"   URL: {settings.surreal_url}")
    print(f"   Namespace: {settings.surreal_namespace}")
    print(f"   Database: {settings.surreal_database}")
    try:
        agno_db_service = get_agno_db_service()
        agno_db = agno_db_service.get_agno_db()
        print("   ‚úÖ SurrealDB accessible")
        checks.append(("SurrealDB", True))
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        print("   üí° Solution: docker-compose up -d surrealdb")
        checks.append(("SurrealDB", False))

    # 2. Ollama (optionnel)
    print("\nü¶ô 2. V√©rification Ollama (optionnel)...")
    try:
        import httpx
        response = httpx.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code == 200:
            models = response.json().get("models", [])
            print(f"   ‚úÖ Ollama accessible ({len(models)} mod√®les)")
            for model in models[:5]:  # Top 5
                print(f"      - {model['name']}")
            checks.append(("Ollama", True))
        else:
            print(f"   ‚ö†Ô∏è  Ollama r√©pond mais erreur: {response.status_code}")
            checks.append(("Ollama", False))
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Ollama non accessible: {e}")
        print("   üí° Solution: ollama serve")
        checks.append(("Ollama", False))

    # 3. Claude API (optionnel)
    print("\n‚òÅÔ∏è  3. V√©rification Claude API (optionnel)...")
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if api_key:
        masked = api_key[:10] + "..." + api_key[-4:]
        print(f"   ‚úÖ ANTHROPIC_API_KEY configur√©e: {masked}")
        checks.append(("Claude API", True))
    else:
        print("   ‚ö†Ô∏è  ANTHROPIC_API_KEY non configur√©e")
        print("   üí° Solution: export ANTHROPIC_API_KEY=sk-ant-...")
        checks.append(("Claude API", False))

    # 4. MLX (optionnel)
    print("\nüçé 4. V√©rification MLX server (optionnel)...")
    try:
        import httpx
        response = httpx.get("http://localhost:8080/v1/models", timeout=2)
        if response.status_code == 200:
            print("   ‚úÖ MLX server accessible")
            checks.append(("MLX", True))
        else:
            print(f"   ‚ö†Ô∏è  MLX server r√©pond mais erreur: {response.status_code}")
            checks.append(("MLX", False))
    except Exception as e:
        print(f"   ‚ö†Ô∏è  MLX server non accessible: {e}")
        print("   üí° Solution: mlx_lm.server --model MODEL_PATH --port 8080")
        checks.append(("MLX", False))

    # 5. Patterns Agno
    print("\nüîß 5. V√©rification patterns Agno...")
    try:
        from agno.agent import Agent
        from agno.workflow import Workflow
        from agno.db.surrealdb import SurrealDb
        print("   ‚úÖ Agno imports OK (Agent, Workflow, SurrealDb)")
        checks.append(("Agno patterns", True))
    except ImportError as e:
        print(f"   ‚ùå Erreur import Agno: {e}")
        checks.append(("Agno patterns", False))

    # 6. Model factory
    print("\nüè≠ 6. V√©rification model factory...")
    try:
        # Test validation
        provider, model_id = validate_model_string("ollama:mistral")
        assert provider == "ollama"
        assert model_id == "mistral"
        print("   ‚úÖ Model factory OK")
        checks.append(("Model factory", True))
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        checks.append(("Model factory", False))

    # R√©sum√©
    print("\n" + "=" * 80)
    print("R√âSUM√â DES V√âRIFICATIONS")
    print("=" * 80)
    for check_name, success in checks:
        status = "‚úÖ" if success else "‚ùå"
        print(f"{status} {check_name}")

    critical_checks = ["SurrealDB", "Agno patterns", "Model factory"]
    critical_passed = all(
        success for name, success in checks if name in critical_checks
    )

    if not critical_passed:
        print("\n‚ùå VALIDATION √âCHOU√âE - V√©rifications critiques manquantes")
        return False

    print("\n‚úÖ VALIDATION R√âUSSIE - Environnement pr√™t pour les tests")
    return True


# ========================================
# G√©n√©ration de PDFs de test
# ========================================

def generate_test_pdfs(output_dir: Path) -> list[Path]:
    """G√©n√®re des PDFs de test si n√©cessaire."""
    output_dir.mkdir(parents=True, exist_ok=True)

    test_pdf = output_dir / "test_vente_sprint1.pdf"

    if test_pdf.exists():
        logger.info(f"‚úÖ PDF de test existe d√©j√†: {test_pdf}")
        return [test_pdf]

    logger.info("üìÑ G√©n√©ration de PDF de test...")

    try:
        from reportlab.lib.pagesizes import letter
        from reportlab.lib.units import inch
        from reportlab.pdfgen import canvas

        c = canvas.Canvas(str(test_pdf), pagesize=letter)
        width, height = letter

        # Titre
        c.setFont("Helvetica-Bold", 16)
        c.drawString(inch, height - inch, "PROMESSE D'ACHAT-VENTE")

        c.setFont("Helvetica", 12)
        y = height - 1.5 * inch

        # Contenu
        content = [
            "",
            "Date: 15 janvier 2025",
            "",
            "VENDEUR: M. Jean Tremblay",
            "Adresse: 123 Rue Principale, Montr√©al, QC H2X 1Y5",
            "",
            "ACHETEUR: Mme Marie Gagnon",
            "Adresse: 456 Avenue des √ârables, Laval, QC H7T 2R3",
            "",
            "PROPRI√âT√â:",
            "Adresse: 789 Rue Saint-Denis, Montr√©al, QC H2S 3L3",
            "Type: Maison unifamiliale",
            "",
            "PRIX DE VENTE: 450 000 $",
            "Mise de fonds: 90 000 $",
            "Hypoth√®que: 360 000 $",
            "",
            "Date de signature: 15 janvier 2025",
            "Date de transfert: 1er mars 2025",
            "",
            "Document g√©n√©r√© pour tests - Sprint 1"
        ]

        for line in content:
            c.drawString(inch, y, line)
            y -= 0.3 * inch

        c.save()
        logger.info(f"‚úÖ PDF cr√©√©: {test_pdf}")
        return [test_pdf]

    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration PDF: {e}")
        return []


# ========================================
# Tests du workflow
# ========================================

async def test_workflow_with_model(
    model_string: str,
    pdf_files: list[Path],
    agno_db
) -> dict:
    """
    Teste le workflow avec un mod√®le sp√©cifique.

    Args:
        model_string: String de configuration (ex: "ollama:mistral")
        pdf_files: Fichiers PDF √† analyser
        agno_db: Instance SurrealDb pour persistance

    Returns:
        Dictionnaire avec les r√©sultats
    """
    print("\n" + "=" * 80)
    print(f"TEST WORKFLOW: {model_string}")
    print("=" * 80)

    start_time = datetime.now()

    try:
        # 1. Valider la string
        provider, model_id = validate_model_string(model_string)
        print(f"‚úÖ Validation OK: provider={provider}, model={model_id}")

        # 2. Cr√©er le mod√®le
        print(f"\nüì¶ Cr√©ation du mod√®le...")
        model = create_model(model_string)
        print(f"‚úÖ Mod√®le cr√©√©: {model}")

        # 3. Cr√©er le workflow avec persistance Agno
        print(f"\nüîß Cr√©ation du workflow avec persistance SurrealDB...")
        workflow = WorkflowAnalyseDossier(
            model=model,
            db=agno_db  # ‚úÖ Persistance automatique
        )
        print(f"‚úÖ Workflow cr√©√© avec persistance automatique")

        # 4. Pr√©parer les m√©tadonn√©es
        metadata = {
            "nom_dossier": f"Test Sprint 1 - {model_string}",
            "type_attendu": "vente",
            "nb_documents": len(pdf_files),
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "model_used": model_string,
        }

        # 5. Ex√©cuter le workflow
        print(f"\nüöÄ Ex√©cution du workflow...")
        print(f"   Documents: {len(pdf_files)} PDF(s)")

        resultat = await workflow.arun(
            fichiers_pdf=[str(f) for f in pdf_files],
            metadata=metadata,
        )

        # 6. Analyser le r√©sultat
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # WorkflowRunOutput d'Agno - extraire le contenu
        if hasattr(resultat, 'content'):
            content = resultat.content
        else:
            content = resultat

        # Extraire les donn√©es du r√©sultat
        if isinstance(content, dict):
            success = content.get("success", True)
            score = content.get("score_confiance", 0.0)
            etapes = content.get("etapes_completees", [])
        else:
            # Si le workflow s'est ex√©cut√©, c'est un succ√®s
            success = True
            score = 0.0
            etapes = []

        print(f"\nüìä R√âSULTATS:")
        print(f"   Succ√®s: {'‚úÖ OUI' if success else '‚ùå NON'}")
        print(f"   Dur√©e: {duration:.2f}s")

        if success:
            print(f"   Score de confiance: {score:.2%}")
            if etapes:
                print(f"   √âtapes compl√©t√©es: {etapes}")

            # Essayer d'extraire la checklist
            if isinstance(content, dict) and "checklist" in content:
                checklist = content["checklist"]
                if isinstance(checklist, dict):
                    nb_items = len(checklist.get("checklist", []))
                    print(f"   Checklist: {nb_items} items g√©n√©r√©s")

        return {
            "model": model_string,
            "provider": provider,
            "success": success,
            "duration_seconds": duration,
            "score_confiance": score,
            "metadata": metadata,
            "resultat": content,
        }

    except Exception as e:
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        print(f"\n‚ùå ERREUR: {e}")
        import traceback
        traceback.print_exc()

        return {
            "model": model_string,
            "provider": provider if 'provider' in locals() else "unknown",
            "success": False,
            "duration_seconds": duration,
            "error": str(e),
        }


# ========================================
# Main
# ========================================

async def main():
    """Point d'entr√©e principal."""
    print("\n")
    print("‚ïî" + "‚ïê" * 78 + "‚ïó")
    print("‚ïë" + " " * 20 + "VALIDATION SPRINT 1 - NOTARY ASSISTANT" + " " * 20 + "‚ïë")
    print("‚ïö" + "‚ïê" * 78 + "‚ïù")
    print("\n")

    # 1. Afficher les mod√®les support√©s
    print_models_info()
    print("\n")

    # 2. Valider l'environnement
    if not validate_environment():
        print("\n‚ùå Validation environnement √©chou√©e. Corrigez les erreurs ci-dessus.")
        return 1

    # 3. Pr√©parer les PDFs de test
    print("\n" + "=" * 80)
    print("PR√âPARATION DES DONN√âES DE TEST")
    print("=" * 80)

    test_data_dir = Path(__file__).parent / "data" / "uploads"
    pdf_files = generate_test_pdfs(test_data_dir)

    if not pdf_files:
        print("‚ùå Aucun PDF de test disponible")
        return 1

    print(f"‚úÖ {len(pdf_files)} PDF(s) de test pr√™t(s)")

    # 4. R√©cup√©rer AgnoDBService
    print("\n" + "=" * 80)
    print("INITIALISATION AGNO DB SERVICE")
    print("=" * 80)

    agno_db_service = get_agno_db_service()
    agno_db = agno_db_service.get_agno_db()
    print("‚úÖ AgnoDBService initialis√©")

    # 5. D√©terminer quels mod√®les tester
    test_all_ollama = os.getenv("TEST_ALL_OLLAMA", "0") == "1"
    model_env = os.getenv("MODEL")

    models_to_test = []

    if test_all_ollama:
        # Tester tous les mod√®les Ollama recommand√©s
        recommended = get_recommended_ollama_models()
        models_to_test = [f"ollama:{m}" for m in recommended]
        print(f"\nü¶ô Mode: Test tous les mod√®les Ollama recommand√©s ({len(models_to_test)})")
    elif model_env:
        # Tester un mod√®le sp√©cifique
        models_to_test = [model_env]
        print(f"\nüéØ Mode: Test d'un mod√®le sp√©cifique")
    else:
        # D√©faut: Ollama mistral
        models_to_test = ["ollama:mistral"]
        print(f"\nü¶ô Mode: Test du mod√®le par d√©faut (Ollama mistral)")

    print(f"\nMod√®les √† tester: {', '.join(models_to_test)}")

    # 6. Ex√©cuter les tests
    print("\n" + "=" * 80)
    print("EX√âCUTION DES TESTS")
    print("=" * 80)

    results = []
    for model_string in models_to_test:
        result = await test_workflow_with_model(
            model_string=model_string,
            pdf_files=pdf_files,
            agno_db=agno_db
        )
        results.append(result)

        # Pause entre les tests
        if len(models_to_test) > 1:
            print("\n‚è∏Ô∏è  Pause 2s avant le prochain test...")
            await asyncio.sleep(2)

    # 7. R√©sum√© final
    print("\n" + "‚ïî" + "‚ïê" * 78 + "‚ïó")
    print("‚ïë" + " " * 28 + "R√âSUM√â FINAL" + " " * 38 + "‚ïë")
    print("‚ïö" + "‚ïê" * 78 + "‚ïù")

    print(f"\nNombre de tests: {len(results)}")
    print("\n" + "-" * 80)
    print(f"{'Mod√®le':<40} | {'Succ√®s':<8} | {'Dur√©e':<10} | {'Score':<10}")
    print("-" * 80)

    for result in results:
        model = result["model"]
        success = "‚úÖ OUI" if result["success"] else "‚ùå NON"
        duration = f"{result['duration_seconds']:.2f}s"
        score = f"{result.get('score_confiance', 0):.2%}" if result["success"] else "N/A"

        print(f"{model:<40} | {success:<8} | {duration:<10} | {score:<10}")

    print("-" * 80)

    # Statistiques
    total = len(results)
    success_count = sum(1 for r in results if r["success"])
    success_rate = (success_count / total * 100) if total > 0 else 0

    print(f"\nüìä Taux de succ√®s: {success_count}/{total} ({success_rate:.1f}%)")

    if success_count == total:
        print("\nüéâ ‚úÖ TOUS LES TESTS ONT R√âUSSI!")
        return 0
    elif success_count > 0:
        print(f"\n‚ö†Ô∏è  CERTAINS TESTS ONT √âCHOU√â ({total - success_count}/{total})")
        return 1
    else:
        print("\n‚ùå TOUS LES TESTS ONT √âCHOU√â")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
