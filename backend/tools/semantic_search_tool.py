"""
Semantic search tool for the Agno agent.

This tool allows the AI agent to perform semantic (vector similarity) search
through documents in a case using natural language queries.
"""

import logging
from typing import Optional

from agno.tools import tool

from services.document_indexing_service import get_document_indexing_service
from services.surreal_service import get_surreal_service

logger = logging.getLogger(__name__)


@tool(name="semantic_search")
async def semantic_search(
    case_id: str,
    query: str,
    top_k: int = 5
) -> str:
    """
    Recherche s√©mantique dans les documents d'un dossier.

    ‚ö†Ô∏è OUTIL PRINCIPAL: Utilisez cet outil pour TOUTE question de l'utilisateur.
    Cet outil utilise l'IA pour comprendre le sens de la question et trouve les passages pertinents dans les documents.

    **R√àGLE ABSOLUE**: TOUJOURS utiliser cet outil en premier pour r√©pondre aux questions, qu'elles soient g√©n√©rales ou sp√©cifiques.

    Exemples de questions √† traiter avec cet outil:
    - "Qu'est-ce que le notariat ?" ‚Üí Cherche dans les documents si le sujet est abord√©
    - "Quel est le prix mentionn√© dans ce contrat ?" ‚Üí Cherche les informations de prix
    - "Explique-moi les obligations du vendeur" ‚Üí Cherche les passages sur les obligations
    - "R√©sume ce document" ‚Üí Cherche les points cl√©s dans le document
    - "Comment fonctionne X ?" ‚Üí Cherche les explications sur X dans les documents

    Si la recherche ne trouve rien de pertinent, vous DEVEZ informer l'utilisateur que l'information
    n'est pas disponible dans les documents du dossier.

    DIFF√âRENCE avec search_documents:
    - search_documents: Recherche de mots-cl√©s exacts (ex: "signature")
    - semantic_search: Comprend le sens de la question (ex: "quelles sont les obligations du vendeur ?")

    Args:
        case_id: L'identifiant du dossier (ex: "1f9fc70e" ou "judgment:1f9fc70e")
        query: La question de l'utilisateur (ex: "qu'est-ce que le notariat ?")
        top_k: Nombre de passages pertinents √† retourner (d√©faut: 5)

    Returns:
        Les passages les plus pertinents avec leur score de pertinence
    """
    try:
        logger.info(f"[semantic_search] START - case_id={case_id}, query={query[:50]}...")

        # Obtenir le service d'indexation
        indexing_service = get_document_indexing_service()
        logger.info(f"[semantic_search] Got indexing service: {indexing_service}")

        # Normaliser case_id
        case_id = case_id
        if not case_id.startswith("case:"):
            case_id = f"judgment:{case_id}"

        logger.info(f"[semantic_search] Normalized case_id: {case_id}")

        # V√©rifier si des documents sont index√©s
        logger.info(f"[semantic_search] Getting index stats for {case_id}...")
        stats = await indexing_service.get_index_stats(case_id=case_id)
        logger.info(f"[semantic_search] Stats: {stats}")

        if stats.get("total_chunks", 0) == 0:
            return """Les documents de ce dossier ne sont pas encore index√©s pour la recherche s√©mantique.

Pour utiliser la recherche s√©mantique:
1. Les documents avec du texte extrait sont automatiquement index√©s lors de l'upload
2. Vous pouvez utiliser l'outil `index_document_tool` pour indexer manuellement un document

En attendant, je ne peux pas r√©pondre √† votre question car je n'ai pas acc√®s au contenu des documents."""

        # Effectuer la recherche s√©mantique
        logger.info(f"[semantic_search] Searching with query='{query}', top_k={top_k}...")
        results = await indexing_service.search_similar(
            query_text=query,
            case_id=case_id,
            top_k=top_k,
            min_similarity=0.5  # Score minimum de similarit√©
        )
        logger.info(f"[semantic_search] Found {len(results)} results")

        if not results:
            return f"""Je n'ai pas trouv√© d'information pertinente sur "{query}" dans les documents du dossier.

Cela peut signifier que:
- Les documents ne contiennent pas d'informations sur ce sujet
- Le score de similarit√© est trop faible (< 50%)

Vous pouvez:
- Reformuler votre question de mani√®re diff√©rente
- V√©rifier si les documents du dossier traitent bien de ce sujet"""

        # R√©cup√©rer les informations des documents sources
        logger.info(f"[semantic_search] Getting surreal service...")
        surreal_service = get_surreal_service()
        logger.info(f"[semantic_search] Surreal service DB connected: {surreal_service.db is not None}")

        if not surreal_service.db:
            logger.info(f"[semantic_search] Connecting to SurrealDB...")
            await surreal_service.connect()

        # Construire une map document_id -> nom_fichier
        doc_ids = list(set([r["document_id"] for r in results]))
        logger.info(f"[semantic_search] Fetching names for {len(doc_ids)} unique documents...")
        doc_names = {}

        for doc_id in doc_ids:
            # Use type::thing() to properly handle UUIDs with dashes
            doc_result = await surreal_service.query(
                "SELECT nom_fichier FROM type::thing($table, $id)",
                {"table": "document", "id": doc_id.replace("document:", "")}
            )
            if doc_result and len(doc_result) > 0:
                first_item = doc_result[0]
                if isinstance(first_item, dict):
                    if "result" in first_item and first_item["result"]:
                        doc_names[doc_id] = first_item["result"][0].get("nom_fichier", doc_id)
                    else:
                        doc_names[doc_id] = first_item.get("nom_fichier", doc_id)
                else:
                    doc_names[doc_id] = doc_id

        # Formater la r√©ponse
        response = f'J\'ai trouv√© **{len(results)} passages pertinents** pour la question: "{query}"\n\n'

        for idx, result in enumerate(results, 1):
            doc_id = result["document_id"]
            doc_name = doc_names.get(doc_id, "Document inconnu")
            chunk_text = result["chunk_text"]
            similarity = result["similarity_score"]

            # Convertir le score en pourcentage
            similarity_pct = int(similarity * 100)

            response += f"### R√©sultat {idx}: {doc_name} (Pertinence: {similarity_pct}%)\n"
            response += f"{chunk_text}\n\n"
            response += "---\n\n"

        # Ajouter une note explicative
        response += f"""*Note: La recherche s√©mantique utilise l'intelligence artificielle pour comprendre le sens de votre question.*
*Les passages sont class√©s par ordre de pertinence (similarit√© vectorielle).*
*Mod√®le utilis√©: {stats.get('embedding_model', 'inconnu')}*"""

        return response.strip()

    except Exception as e:
        logger.error(f"Semantic search error: {e}", exc_info=True)
        return f"Erreur lors de la recherche s√©mantique: {str(e)}"


@tool(name="index_document")
async def index_document_tool(
    case_id: str,
    document_name: str
) -> str:
    """
    Indexe un document pour la recherche s√©mantique.

    Cet outil permet d'indexer manuellement un document si l'indexation automatique
    n'a pas fonctionn√© ou si vous voulez forcer la r√©indexation.

    Args:
        case_id: L'identifiant du dossier
        document_name: Nom du fichier √† indexer

    Returns:
        R√©sultat de l'indexation
    """
    try:
        # Normaliser case_id
        case_id = case_id
        if not case_id.startswith("case:"):
            case_id = f"judgment:{case_id}"

        # R√©cup√©rer le document
        surreal_service = get_surreal_service()
        if not surreal_service.db:
            await surreal_service.connect()

        doc_result = await surreal_service.query(
            "SELECT * FROM document WHERE case_id = $case_id AND nom_fichier = $nom_fichier",
            {"case_id": case_id, "nom_fichier": document_name}
        )

        documents = []
        if doc_result and len(doc_result) > 0:
            first_item = doc_result[0]
            if isinstance(first_item, dict) and "result" in first_item:
                documents = first_item["result"] if isinstance(first_item["result"], list) else []
            elif isinstance(first_item, list):
                documents = first_item
            elif isinstance(first_item, dict):
                documents = doc_result

        if not documents:
            return f"Document '{document_name}' non trouv√© dans le dossier {case_id}."

        document = documents[0]
        doc_id = document.get("id")
        texte_extrait = document.get("texte_extrait", "")

        if not texte_extrait:
            return f"Le document '{document_name}' n'a pas de texte extrait. L'indexation n√©cessite du contenu textuel."

        # Indexer le document
        indexing_service = get_document_indexing_service()
        result = await indexing_service.index_document(
            document_id=doc_id,
            case_id=case_id,
            text_content=texte_extrait,
            force_reindex=True  # Forcer la r√©indexation
        )

        if result["success"]:
            chunks_created = result.get("chunks_created", 0)
            embedding_model = result.get("embedding_model", "inconnu")
            return f"‚úÖ Document '{document_name}' index√© avec succ√®s!\n\n- {chunks_created} segments cr√©√©s\n- Mod√®le: {embedding_model}\n\nLe document est maintenant disponible pour la recherche s√©mantique."
        else:
            error = result.get("error", "Erreur inconnue")
            return f"‚ùå √âchec de l'indexation: {error}"

    except Exception as e:
        logger.error(f"Index document error: {e}", exc_info=True)
        return f"Erreur lors de l'indexation du document: {str(e)}"


@tool(name="get_index_stats")
async def get_index_stats(case_id: str) -> str:
    """
    Affiche les statistiques de l'index de recherche s√©mantique pour un dossier.

    Args:
        case_id: L'identifiant du dossier

    Returns:
        Statistiques de l'index
    """
    try:
        # Normaliser case_id
        case_id = case_id
        if not case_id.startswith("case:"):
            case_id = f"judgment:{case_id}"

        indexing_service = get_document_indexing_service()
        stats = await indexing_service.get_index_stats(case_id=case_id)

        if "error" in stats:
            return f"Erreur lors de la r√©cup√©ration des statistiques: {stats['error']}"

        total_chunks = stats.get("total_chunks", 0)
        embedding_model = stats.get("embedding_model", "inconnu")
        embedding_dimensions = stats.get("embedding_dimensions", 0)

        if total_chunks == 0:
            return f"""**Index de recherche s√©mantique pour le dossier {case_id}:**

üìä **Statut:** Aucun document index√©

Pour indexer des documents:
1. Les documents avec du texte extrait sont automatiquement index√©s lors de l'upload
2. Utilisez l'outil `index_document` pour indexer manuellement un document sp√©cifique"""

        return f"""**Index de recherche s√©mantique pour le dossier {case_id}:**

üìä **Statistiques:**
- Segments index√©s: {total_chunks}
- Mod√®le d'embeddings: {embedding_model}
- Dimensions: {embedding_dimensions}

‚úÖ La recherche s√©mantique est disponible pour ce dossier!
Utilisez `semantic_search` pour poser des questions en langage naturel."""

    except Exception as e:
        logger.error(f"Get index stats error: {e}", exc_info=True)
        return f"Erreur lors de la r√©cup√©ration des statistiques: {str(e)}"
