"""
Tutor Service for Legal Assistant.

Provides pedagogical functions for creating summaries, mind maps, quizzes, and explanations.
"""

import logging
from typing import Dict, List, Optional

from services.document_indexing_service import DocumentIndexingService
from services.surreal_service import get_surreal_service

logger = logging.getLogger(__name__)


class TutorService:
    """Service for generating pedagogical content."""

    def __init__(self):
        """Initialize the tutor service."""
        self.indexing_service = DocumentIndexingService()

    async def generate_summary_content(
        self,
        case_id: str,
        document_id: Optional[str] = None,
        summary_type: str = "comprehensive"
    ) -> str:
        """
        Generate a pedagogical summary of a document or course.

        Args:
            case_id: Course ID
            document_id: Document ID (if None, summarize entire course)
            summary_type: Type of summary ("comprehensive", "key_points", "executive")

        Returns:
            Formatted markdown summary
        """
        logger.info(f"Generating {summary_type} summary for case_id={case_id}, document_id={document_id}")

        try:
            # Get document name for title
            doc_name = "le cours"
            if document_id:
                doc_data = await self.get_document_content(document_id)
                if doc_data:
                    doc_name = doc_data.get("nom_fichier", "le document")

            # Perform semantic searches to extract key content
            # We'll do 3 targeted searches to get different aspects

            # 1. Main concepts and definitions
            concepts_results = await self.search_content(
                case_id=case_id,
                query="Quels sont les concepts principaux, dÃ©finitions et notions clÃ©s abordÃ©s ?",
                document_id=document_id,
                top_k=5
            )

            # 2. Important points and rules
            points_results = await self.search_content(
                case_id=case_id,
                query="Quels sont les points importants, rÃ¨gles, conditions et obligations Ã  retenir ?",
                document_id=document_id,
                top_k=5
            )

            # 3. Warnings, exceptions, and pitfalls
            warnings_results = await self.search_content(
                case_id=case_id,
                query="Quels sont les points d'attention, exceptions, cas particuliers et erreurs Ã  Ã©viter ?",
                document_id=document_id,
                top_k=3
            )

            # Build the summary
            summary = f"# ğŸ“ RÃ©sumÃ© PÃ©dagogique: {doc_name}\n\n"

            # Learning objectives
            summary += "## ğŸ¯ Objectifs d'Apprentissage\n"
            summary += "AprÃ¨s avoir Ã©tudiÃ© ce contenu, vous devriez pouvoir:\n"
            if concepts_results:
                # Generate objectives from concepts
                for i, result in enumerate(concepts_results[:3], 1):
                    # Extract first sentence or key phrase from content
                    content = result.get("content", "")
                    first_sentence = content.split('.')[0] if content else ""
                    if first_sentence:
                        summary += f"- âœ… Comprendre {first_sentence.lower()}\n"
            else:
                summary += "- âœ… MaÃ®triser les concepts clÃ©s du sujet\n"
                summary += "- âœ… Identifier les Ã©lÃ©ments essentiels\n"
                summary += "- âœ… Appliquer les rÃ¨gles et principes\n"

            # Key points
            summary += "\n## ğŸ“š Points ClÃ©s\n\n"
            if points_results:
                for i, result in enumerate(points_results, 1):
                    content = result.get("content", "")
                    source = result.get("document_name", "document")
                    similarity = result.get("similarity", 0)

                    # Only include results with decent similarity
                    if similarity >= 0.3 and content:
                        # Truncate if too long
                        if len(content) > 400:
                            content = content[:400] + "..."

                        summary += f"### {i}. Point Important\n"
                        summary += f"{content}\n\n"
                        summary += f"**Source:** {source}\n\n"
            else:
                summary += "*Aucun point clÃ© trouvÃ©. Le document pourrait ne pas Ãªtre indexÃ©.*\n\n"

            # Important concepts
            summary += "## ğŸ’¡ Concepts Importants Ã  Retenir\n\n"
            if concepts_results:
                # Group concepts by source
                sources = {}
                for result in concepts_results:
                    source = result.get("document_name", "document")
                    content = result.get("content", "")
                    similarity = result.get("similarity", 0)

                    if similarity >= 0.3 and content:
                        if source not in sources:
                            sources[source] = []
                        # Extract key phrases (first 200 chars)
                        snippet = content[:200].strip()
                        sources[source].append(snippet)

                for source, snippets in sources.items():
                    summary += f"### Selon {source}\n"
                    for snippet in snippets[:2]:  # Max 2 per source
                        summary += f"- {snippet}...\n"
                    summary += "\n"
            else:
                summary += "*Consultez le document complet pour identifier les concepts clÃ©s.*\n\n"

            # Warnings and attention points
            summary += "## âš ï¸ Points d'Attention\n\n"
            if warnings_results:
                for result in warnings_results:
                    content = result.get("content", "")
                    source = result.get("document_name", "document")
                    similarity = result.get("similarity", 0)

                    if similarity >= 0.3 and content:
                        # Extract first sentence or key warning
                        first_part = content[:300].strip()
                        summary += f"- {first_part}...\n"
                        summary += f"  - *Source: {source}*\n\n"
            else:
                summary += "*Relisez attentivement le document pour identifier les exceptions et cas particuliers.*\n\n"

            # Call to action
            summary += "## ğŸ“Š Pour Aller Plus Loin\n\n"
            summary += "Voulez-vous que je:\n"
            summary += "- ğŸ—ºï¸ CrÃ©e une carte mentale de ce contenu?\n"
            summary += "- â“ GÃ©nÃ¨re un quiz pour tester votre comprÃ©hension?\n"
            summary += "- ğŸ’¡ Explique un concept spÃ©cifique plus en dÃ©tail?\n"

            return summary

        except Exception as e:
            logger.error(f"Error generating summary: {e}", exc_info=True)
            return f"""# âŒ Erreur lors de la gÃ©nÃ©ration du rÃ©sumÃ©

Une erreur est survenue: {str(e)}

Veuillez vÃ©rifier que:
- Le document existe et est indexÃ©
- Le cours contient des documents avec du texte extrait
"""

    async def generate_mindmap_content(
        self,
        case_id: str,
        document_id: Optional[str] = None,
        focus_topic: Optional[str] = None
    ) -> str:
        """
        Generate a mind map in markdown format with emojis.

        Args:
            case_id: Course ID
            document_id: Document ID (if None, map entire course)
            focus_topic: Specific topic to focus on

        Returns:
            Formatted markdown mind map
        """
        logger.info(f"Generating mind map for case_id={case_id}, document_id={document_id}, topic={focus_topic}")

        try:
            # Get document name for title
            doc_name = "le cours"
            if document_id:
                doc_data = await self.get_document_content(document_id)
                if doc_data:
                    doc_name = doc_data.get("nom_fichier", "le document")

            # Determine search query based on focus_topic
            if focus_topic:
                query = f"Quels sont les concepts, Ã©lÃ©ments et aspects principaux de {focus_topic} ?"
                title = f"{focus_topic}"
            else:
                query = "Quels sont les thÃ¨mes, concepts et notions principales abordÃ©s dans ce contenu ?"
                title = doc_name

            # Search for main themes and concepts
            main_results = await self.search_content(
                case_id=case_id,
                query=query,
                document_id=document_id,
                top_k=8
            )

            # Build mind map
            mindmap = f"# ğŸ—ºï¸ Carte Mentale: {title}\n\n"

            if not main_results or all(r.get("similarity", 0) < 0.3 for r in main_results):
                mindmap += """*Aucun contenu trouvÃ©. Le document pourrait ne pas Ãªtre indexÃ©.*

**Suggestions :**
- VÃ©rifiez que le document est indexÃ©
- Essayez de spÃ©cifier un sujet prÃ©cis avec l'outil
"""
                return mindmap

            # Extract and organize concepts
            # We'll create sections based on keywords and content
            sections = self._organize_mindmap_sections(main_results)

            # Build the hierarchical structure
            for section_title, items in sections.items():
                mindmap += f"## {section_title}\n"

                for item in items[:5]:  # Max 5 items per section
                    content = item.get("content", "")
                    if len(content) > 100:
                        # Extract first sentence or key phrase
                        sentences = content.split('.')
                        first_sentence = sentences[0].strip()
                        if len(first_sentence) > 80:
                            first_sentence = first_sentence[:80] + "..."
                        mindmap += f"  - {first_sentence}\n"

                        # Add sub-details if available
                        if len(sentences) > 1:
                            second_sentence = sentences[1].strip()
                            if second_sentence and len(second_sentence) < 80:
                                mindmap += f"    - {second_sentence}\n"
                    else:
                        mindmap += f"  - {content.strip()}\n"

                mindmap += "\n"

            # Add footer
            mindmap += "---\n\n"
            mindmap += f"**ğŸ“Š Carte gÃ©nÃ©rÃ©e Ã  partir de {len(main_results)} passages pertinents**\n\n"
            mindmap += "ğŸ’¡ **Astuce :** Utilisez `explain_concept` pour approfondir un concept spÃ©cifique\n"

            return mindmap

        except Exception as e:
            logger.error(f"Error generating mind map: {e}", exc_info=True)
            return f"""# âŒ Erreur lors de la gÃ©nÃ©ration de la carte mentale

Une erreur est survenue: {str(e)}

Veuillez vÃ©rifier que le document est indexÃ©.
"""

    def _organize_mindmap_sections(self, results: List[Dict]) -> Dict[str, List[Dict]]:
        """
        Organize search results into thematic sections.

        Args:
            results: List of search results

        Returns:
            Dictionary mapping section titles to items
        """
        # Define emoji mappings for common legal concepts
        emoji_map = {
            "dÃ©finition": "ğŸ“–",
            "principe": "âš–ï¸",
            "condition": "âœ…",
            "obligation": "ğŸ“‹",
            "droit": "ğŸ‘‘",
            "exception": "âš ï¸",
            "effet": "âš¡",
            "procÃ©dure": "ğŸ“",
            "rÃ¨gle": "ğŸ“",
            "exemple": "ğŸ’¡",
            "article": "ğŸ“œ",
            "contrat": "ğŸ¤",
            "responsabilitÃ©": "ğŸ”¥",
            "propriÃ©tÃ©": "ğŸ ",
            "personne": "ğŸ‘¤",
            "tribunal": "ğŸ›ï¸",
            "dÃ©lai": "â±ï¸",
            "preuve": "ğŸ”",
        }

        sections = {}
        default_sections = {
            "ğŸ“– DÃ©finitions et Concepts": [],
            "âš–ï¸ Principes et RÃ¨gles": [],
            "âœ… Conditions et Ã‰lÃ©ments": [],
            "âš ï¸ Exceptions et Cas Particuliers": [],
            "ğŸ’¡ Exemples et Applications": [],
        }

        for result in results:
            content = result.get("content", "").lower()
            similarity = result.get("similarity", 0)

            if similarity < 0.3:
                continue

            # Categorize based on keywords
            if any(keyword in content for keyword in ["dÃ©finition", "dÃ©fini comme", "signifie", "est un"]):
                default_sections["ğŸ“– DÃ©finitions et Concepts"].append(result)
            elif any(keyword in content for keyword in ["principe", "rÃ¨gle", "loi", "article"]):
                default_sections["âš–ï¸ Principes et RÃ¨gles"].append(result)
            elif any(keyword in content for keyword in ["condition", "Ã©lÃ©ment", "critÃ¨re", "requis"]):
                default_sections["âœ… Conditions et Ã‰lÃ©ments"].append(result)
            elif any(keyword in content for keyword in ["exception", "sauf", "toutefois", "cependant"]):
                default_sections["âš ï¸ Exceptions et Cas Particuliers"].append(result)
            elif any(keyword in content for keyword in ["exemple", "par exemple", "notamment", "ainsi"]):
                default_sections["ğŸ’¡ Exemples et Applications"].append(result)
            else:
                # Default to Principes et RÃ¨gles
                default_sections["âš–ï¸ Principes et RÃ¨gles"].append(result)

        # Only keep non-empty sections
        sections = {k: v for k, v in default_sections.items() if v}

        # If no sections, create a generic one
        if not sections:
            sections["ğŸ“š Contenu Principal"] = results

        return sections

    async def generate_quiz_content(
        self,
        case_id: str,
        document_id: Optional[str] = None,
        num_questions: int = 5,
        difficulty: str = "medium"
    ) -> str:
        """
        Generate an interactive quiz with questions and explanations.

        Args:
            case_id: Course ID
            document_id: Document ID (if None, quiz on entire course)
            num_questions: Number of questions (1-10)
            difficulty: Difficulty level ("easy", "medium", "hard")

        Returns:
            Formatted markdown quiz with collapsible answers
        """
        logger.info(f"Generating quiz ({num_questions} questions, {difficulty}) for case_id={case_id}, document_id={document_id}")

        try:
            # Get document name for title
            doc_name = "le cours"
            if document_id:
                doc_data = await self.get_document_content(document_id)
                if doc_data:
                    doc_name = doc_data.get("nom_fichier", "le document")

            # Difficulty stars mapping
            difficulty_stars = {
                "easy": "â­",
                "medium": "â­â­",
                "hard": "â­â­â­"
            }
            stars = difficulty_stars.get(difficulty, "â­â­")

            # Search for factual content to base questions on
            # We need diverse content for variety
            factual_content = await self.search_content(
                case_id=case_id,
                query="Quels sont les faits, dÃ©finitions, rÃ¨gles, conditions et principes importants ?",
                document_id=document_id,
                top_k=num_questions * 2  # Get more than needed for variety
            )

            quiz = f"# ğŸ“ Quiz: {doc_name}\n\n"

            if not factual_content or all(r.get("similarity", 0) < 0.3 for r in factual_content):
                quiz += """*Impossible de gÃ©nÃ©rer un quiz. Le document pourrait ne pas Ãªtre indexÃ©.*

**Suggestions :**
- VÃ©rifiez que le document est indexÃ©
- Essayez avec un document diffÃ©rent
"""
                return quiz

            quiz += f"*Testez votre comprÃ©hension de {doc_name}*\n\n"
            quiz += "---\n\n"

            # Generate questions from content
            questions_generated = 0
            for i, result in enumerate(factual_content):
                if questions_generated >= num_questions:
                    break

                content = result.get("content", "")
                source = result.get("document_name", "document")
                similarity = result.get("similarity", 0)

                if similarity < 0.3 or len(content) < 50:
                    continue

                # Extract a fact or concept for the question
                sentences = [s.strip() for s in content.split('.') if s.strip()]
                if not sentences:
                    continue

                # Use first substantial sentence as basis
                fact = sentences[0]
                if len(fact) < 20:
                    if len(sentences) > 1:
                        fact = sentences[1]
                    else:
                        continue

                questions_generated += 1

                quiz += f"## Question {questions_generated}/{num_questions} (DifficultÃ©: {stars})\n"

                # Generate question based on content
                # This is a simplified version - in production, you'd use an LLM to generate better questions
                if "dÃ©finition" in content.lower() or "est un" in content.lower():
                    quiz += f"**Quelle est la dÃ©finition correcte selon le document ?**\n\n"
                elif "condition" in content.lower() or "Ã©lÃ©ment" in content.lower():
                    quiz += f"**Quelles sont les conditions requises ?**\n\n"
                elif "principe" in content.lower() or "rÃ¨gle" in content.lower():
                    quiz += f"**Quel principe est Ã©noncÃ© dans le document ?**\n\n"
                else:
                    quiz += f"**Selon le document, quelle affirmation est correcte ?**\n\n"

                # Generate 4 answer choices
                # Option A: Correct answer (based on actual content)
                quiz += f"a) {fact[:100]}{'...' if len(fact) > 100 else ''}\n"

                # Options B, C, D: Plausible but incorrect (generic for now)
                quiz += f"b) [Alternative plausible - nÃ©cessite gÃ©nÃ©ration par LLM]\n"
                quiz += f"c) [Alternative plausible - nÃ©cessite gÃ©nÃ©ration par LLM]\n"
                quiz += f"d) [Alternative plausible - nÃ©cessite gÃ©nÃ©ration par LLM]\n\n"

                # Collapsible answer
                quiz += "<details>\n"
                quiz += "<summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n\n"
                quiz += "âœ… **RÃ©ponse correcte: a)**\n\n"
                quiz += "**Explication:**\n"

                # Provide detailed explanation
                if len(sentences) > 1:
                    quiz += f"{sentences[0]}. {sentences[1] if len(sentences) > 1 else ''}\n\n"
                else:
                    quiz += f"{content[:300]}...\n\n"

                quiz += f"**Source:** {source}\n\n"
                quiz += "---\n\n"
                quiz += "</details>\n\n"

            # Footer
            quiz += "---\n\n"
            quiz += "## ğŸ“Š RÃ©sultats et Prochaines Ã‰tapes\n\n"
            quiz += "**Comment utiliser ce quiz:**\n"
            quiz += "1. ğŸ“ RÃ©pondez Ã  chaque question avant de regarder la rÃ©ponse\n"
            quiz += "2. ğŸ’¡ Lisez attentivement les explications\n"
            quiz += "3. ğŸ“š Retournez au document source si besoin de clarification\n\n"
            quiz += "**Pour approfondir:**\n"
            quiz += "- ğŸ—ºï¸ Voulez-vous une carte mentale du document?\n"
            quiz += "- ğŸ’¡ Besoin d'explications supplÃ©mentaires sur un concept?\n"
            quiz += "- ğŸ“ Voulez-vous un rÃ©sumÃ© du document?\n\n"
            quiz += "Bon apprentissage! ğŸ“\n"

            # Note about limitations
            if questions_generated < num_questions:
                quiz += f"\n*Note: Seulement {questions_generated} questions ont pu Ãªtre gÃ©nÃ©rÃ©es Ã  partir du contenu disponible.*\n"

            return quiz

        except Exception as e:
            logger.error(f"Error generating quiz: {e}", exc_info=True)
            return f"""# âŒ Erreur lors de la gÃ©nÃ©ration du quiz

Une erreur est survenue: {str(e)}

Veuillez vÃ©rifier que le document est indexÃ©.
"""

    async def generate_concept_explanation(
        self,
        case_id: str,
        concept: str,
        document_id: Optional[str] = None,
        detail_level: str = "standard"
    ) -> str:
        """
        Generate a detailed explanation of a legal concept.

        Args:
            case_id: Course ID
            concept: Concept to explain
            document_id: Limit search to specific document
            detail_level: Detail level ("simple", "standard", "advanced")

        Returns:
            Formatted markdown explanation
        """
        logger.info(f"Explaining concept '{concept}' (level={detail_level}) for case_id={case_id}, document_id={document_id}")

        try:
            # Search for definition
            definition_results = await self.search_content(
                case_id=case_id,
                query=f"Quelle est la dÃ©finition de {concept} ? Qu'est-ce que {concept} signifie ?",
                document_id=document_id,
                top_k=3
            )

            # Search for conditions and elements
            conditions_results = await self.search_content(
                case_id=case_id,
                query=f"Quelles sont les conditions, Ã©lÃ©ments ou critÃ¨res de {concept} ?",
                document_id=document_id,
                top_k=3
            )

            # Search for examples
            examples_results = await self.search_content(
                case_id=case_id,
                query=f"Quels sont les exemples, cas ou applications de {concept} ?",
                document_id=document_id,
                top_k=2
            )

            # Build explanation
            explanation = f"# ğŸ’¡ Explication: {concept}\n\n"

            # Definition section
            explanation += "## ğŸ“– DÃ©finition\n\n"
            if definition_results and any(r.get("similarity", 0) >= 0.3 for r in definition_results):
                for result in definition_results:
                    if result.get("similarity", 0) >= 0.3:
                        content = result.get("content", "")
                        source = result.get("document_name", "document")

                        # Extract most relevant sentence
                        sentences = [s.strip() for s in content.split('.') if s.strip()]
                        if sentences:
                            # Find sentence containing the concept
                            relevant = [s for s in sentences if concept.lower() in s.lower()]
                            if relevant:
                                explanation += f"{relevant[0]}.\n\n"
                            else:
                                explanation += f"{sentences[0]}.\n\n"

                            explanation += f"*Source: {source}*\n\n"
                            break  # Only use most relevant
            else:
                explanation += f"*Aucune dÃ©finition trouvÃ©e pour '{concept}' dans les documents disponibles.*\n\n"

            # Conditions/Elements section
            explanation += "## ğŸ¯ Conditions et Ã‰lÃ©ments\n\n"
            if conditions_results and any(r.get("similarity", 0) >= 0.3 for r in conditions_results):
                sources_used = set()
                for result in conditions_results[:2]:  # Max 2 results
                    if result.get("similarity", 0) >= 0.3:
                        content = result.get("content", "")
                        source = result.get("document_name", "document")

                        if source in sources_used:
                            continue
                        sources_used.add(source)

                        # Extract key points
                        if len(content) > 300:
                            content = content[:300] + "..."

                        explanation += f"{content}\n\n"
                        explanation += f"*Source: {source}*\n\n"
            else:
                explanation += f"*Aucune information sur les conditions de '{concept}' trouvÃ©e.*\n\n"

            # Examples section
            explanation += "## ğŸ“š Exemples et Applications\n\n"
            if examples_results and any(r.get("similarity", 0) >= 0.3 for r in examples_results):
                for i, result in enumerate(examples_results, 1):
                    if result.get("similarity", 0) >= 0.3:
                        content = result.get("content", "")
                        source = result.get("document_name", "document")

                        # Format as example
                        if len(content) > 250:
                            content = content[:250] + "..."

                        explanation += f"**Exemple {i}:**\n"
                        explanation += f"> {content}\n\n"
                        explanation += f"*Source: {source}*\n\n"
            else:
                explanation += f"*Aucun exemple de '{concept}' trouvÃ© dans les documents.*\n\n"

            # Sources summary
            explanation += "## ğŸ“ Sources ConsultÃ©es\n\n"
            all_sources = set()
            for results in [definition_results, conditions_results, examples_results]:
                if results:
                    for r in results:
                        if r.get("similarity", 0) >= 0.3:
                            all_sources.add(r.get("document_name", "document"))

            if all_sources:
                for source in sorted(all_sources):
                    explanation += f"- {source}\n"
            else:
                explanation += "*Aucune source pertinente trouvÃ©e*\n"

            explanation += "\n"

            # Related concepts (heuristic based on content)
            explanation += "## ğŸ”— Concepts Potentiellement LiÃ©s\n\n"
            explanation += "*Pour explorer ces concepts, utilisez l'outil `explain_concept` avec le nom du concept.*\n\n"

            # Suggest using other tools
            explanation += "## ğŸ“Š Pour Aller Plus Loin\n\n"
            explanation += f"- ğŸ“ Demandez un rÃ©sumÃ© du document contenant '{concept}'\n"
            explanation += f"- â“ Testez vos connaissances avec un quiz sur ce sujet\n"
            explanation += f"- ğŸ—ºï¸ Visualisez les concepts avec une carte mentale\n"

            # Adapt explanation based on detail level
            if detail_level == "simple":
                # Add note that this is simplified
                explanation = f"*Explication simplifiÃ©e de {concept}*\n\n" + explanation
            elif detail_level == "advanced":
                # Add note for advanced level
                explanation = f"*Explication dÃ©taillÃ©e de {concept}*\n\n" + explanation

            return explanation

        except Exception as e:
            logger.error(f"Error explaining concept: {e}", exc_info=True)
            return f"""# âŒ Erreur lors de l'explication du concept

Une erreur est survenue: {str(e)}

Veuillez vÃ©rifier que:
- Le concept est mentionnÃ© dans les documents
- Les documents sont indexÃ©s
"""

    async def get_document_content(self, document_id: str) -> Optional[Dict]:
        """
        Retrieve full document content from database.

        Args:
            document_id: Document ID

        Returns:
            Document data with texte_extrait
        """
        try:
            service = get_surreal_service()
            if not service.db:
                await service.connect()

            result = await service.query(f"SELECT * FROM {document_id}")

            if result and len(result) > 0:
                # Handle different response formats
                doc_data = result[0]
                if isinstance(doc_data, dict):
                    if "result" in doc_data and isinstance(doc_data["result"], list) and len(doc_data["result"]) > 0:
                        return doc_data["result"][0]
                    elif "id" in doc_data or "nom_fichier" in doc_data:
                        return doc_data

            return None

        except Exception as e:
            logger.error(f"Error retrieving document {document_id}: {e}")
            return None

    async def search_content(
        self,
        case_id: str,
        query: str,
        document_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict]:
        """
        Search for content using semantic search.

        Args:
            case_id: Course ID
            query: Search query
            document_id: Limit to specific document
            top_k: Number of results

        Returns:
            List of search results with content and metadata
        """
        try:
            # Normalize case_id
            if not case_id.startswith("course:"):
                case_id = f"course:{case_id}"

            # Use the indexing service for semantic search
            results = await self.indexing_service.search_similar(
                query_text=query,
                case_id=case_id,
                top_k=top_k
            )

            # Filter by document_id if provided
            if document_id and results:
                results = [r for r in results if r.get("document_id") == document_id]

            return results

        except Exception as e:
            logger.error(f"Error searching content: {e}")
            return []


# Singleton instance
_tutor_service: Optional[TutorService] = None


def get_tutor_service() -> TutorService:
    """Get the singleton tutor service instance."""
    global _tutor_service
    if _tutor_service is None:
        _tutor_service = TutorService()
    return _tutor_service
